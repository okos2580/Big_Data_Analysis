"""
ì£¼ì‹ ê°€ê²© ì˜ˆì¸¡ ëª¨ë“ˆ
ë‹¤ì–‘í•œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
import warnings
warnings.filterwarnings('ignore')

# ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ (TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬)
# import tensorflow as tf
# from tensorflow.keras.models import Sequential
# from tensorflow.keras.layers import LSTM, Dense, Dropout
# from tensorflow.keras.optimizers import Adam
# from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# ì‹œê°í™”
import matplotlib
matplotlib.use('Agg')  # GUI ì—†ëŠ” ë°±ì—”ë“œ ì‚¬ìš©
import matplotlib.pyplot as plt
import seaborn as sns

class StockPredictor:
    def __init__(self):
        """ì£¼ê°€ ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”"""
        os.makedirs('results/models', exist_ok=True)
        os.makedirs('results/predictions', exist_ok=True)
        
        # ëª¨ë¸ ì €ì¥ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
        self.models = {}
        self.scalers = {}
        self.predictions = {}
        
        # í‰ê°€ ì§€í‘œ ì €ì¥
        self.evaluation_results = {}
        
    def load_data(self, filepath):
        """
        ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
        
        Args:
            filepath (str): ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            
        Returns:
            pd.DataFrame: ë¡œë“œëœ ë°ì´í„°
        """
        try:
            data = pd.read_csv(filepath, encoding='utf-8-sig', index_col=0, parse_dates=True)
            print(f"âœ“ ì˜ˆì¸¡ìš© ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {filepath}")
            return data
        except Exception as e:
            print(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def prepare_features(self, data, target_column='Close', prediction_days=5):
        """
        ì˜ˆì¸¡ì„ ìœ„í•œ íŠ¹ì„±ê³¼ íƒ€ê²Ÿì„ ì¤€ë¹„í•©ë‹ˆë‹¤.
        
        Args:
            data (pd.DataFrame): ì£¼ì‹ ë°ì´í„°
            target_column (str): ì˜ˆì¸¡í•  ì»¬ëŸ¼
            prediction_days (int): ì˜ˆì¸¡ ì¼ìˆ˜
            
        Returns:
            tuple: (X, y, feature_names)
        """
        # ì˜ˆì¸¡ì— ì‚¬ìš©í•  íŠ¹ì„±ë“¤
        feature_columns = [
            'Open', 'High', 'Low', 'Close', 'Volume',
            'MA_5', 'MA_10', 'MA_20', 'MA_50',
            'RSI', 'MACD', 'MACD_Signal',
            'BB_Upper', 'BB_Lower', 'BB_Position',
            'Daily_Return', 'Volatility',
            'DayOfWeek', 'Month', 'Quarter'
        ]
        
        # ì§€ì—° íŠ¹ì„± í¬í•¨
        lag_features = [col for col in data.columns if '_lag_' in col]
        feature_columns.extend(lag_features)
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„±ë§Œ ì„ íƒ
        available_features = [col for col in feature_columns if col in data.columns]
        
        # íŠ¹ì„± ë°ì´í„° ì¤€ë¹„
        X = data[available_features].copy()
        
        # íƒ€ê²Ÿ ë³€ìˆ˜: Nì¼ í›„ ì¢…ê°€
        y = data[target_column].shift(-prediction_days)
        
        # ê²°ì¸¡ì¹˜ ì œê±°
        valid_indices = ~(X.isnull().any(axis=1) | y.isnull())
        X = X[valid_indices]
        y = y[valid_indices]
        
        print(f"âœ“ íŠ¹ì„± ì¤€ë¹„ ì™„ë£Œ: {len(available_features)}ê°œ íŠ¹ì„±, {len(X)}ê°œ ìƒ˜í”Œ")
        print(f"ì˜ˆì¸¡ ëŒ€ìƒ: {prediction_days}ì¼ í›„ {target_column}")
        
        return X, y, available_features
    
    def split_time_series_data(self, X, y, test_size=0.2, validation_size=0.2):
        """
        ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ì‹œê°„ ìˆœì„œë¥¼ ê³ ë ¤í•˜ì—¬ ë¶„í• í•©ë‹ˆë‹¤.
        
        Args:
            X (pd.DataFrame): íŠ¹ì„± ë°ì´í„°
            y (pd.Series): íƒ€ê²Ÿ ë°ì´í„°
            test_size (float): í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¹„ìœ¨
            validation_size (float): ê²€ì¦ ì„¸íŠ¸ ë¹„ìœ¨
            
        Returns:
            tuple: (X_train, X_val, X_test, y_train, y_val, y_test)
        """
        n_samples = len(X)
        
        # ì‹œê°„ ìˆœì„œë¥¼ ê³ ë ¤í•œ ë¶„í• 
        train_end = int(n_samples * (1 - test_size - validation_size))
        val_end = int(n_samples * (1 - test_size))
        
        X_train = X.iloc[:train_end]
        X_val = X.iloc[train_end:val_end]
        X_test = X.iloc[val_end:]
        
        y_train = y.iloc[:train_end]
        y_val = y.iloc[train_end:val_end]
        y_test = y.iloc[val_end:]
        
        print(f"âœ“ ë°ì´í„° ë¶„í•  ì™„ë£Œ:")
        print(f"  - í›ˆë ¨: {len(X_train)} ìƒ˜í”Œ")
        print(f"  - ê²€ì¦: {len(X_val)} ìƒ˜í”Œ")
        print(f"  - í…ŒìŠ¤íŠ¸: {len(X_test)} ìƒ˜í”Œ")
        
        return X_train, X_val, X_test, y_train, y_val, y_test
    
    def train_traditional_models(self, X_train, X_val, X_test, y_train, y_val, y_test):
        """
        ì „í†µì ì¸ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë“¤ì„ í›ˆë ¨í•©ë‹ˆë‹¤.
        
        Args:
            X_train, X_val, X_test: íŠ¹ì„± ë°ì´í„°
            y_train, y_val, y_test: íƒ€ê²Ÿ ë°ì´í„°
        """
        print("ğŸ¤– ì „í†µì ì¸ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
        
        # ë°ì´í„° ì •ê·œí™”
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_val_scaled = scaler.transform(X_val)
        X_test_scaled = scaler.transform(X_test)
        
        self.scalers['traditional'] = scaler
        
        # ëª¨ë¸ ì •ì˜
        models = {
            'Linear Regression': LinearRegression(),
            'Ridge Regression': Ridge(alpha=1.0),
            'Lasso Regression': Lasso(alpha=0.1),
            'Random Forest': RandomForestRegressor(
                n_estimators=100, 
                max_depth=10, 
                random_state=42,
                n_jobs=-1
            ),
            'Gradient Boosting': GradientBoostingRegressor(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                random_state=42
            ),
            'Support Vector Regression': SVR(
                kernel='rbf',
                C=100,
                gamma='scale'
            )
        }
        
        # ê° ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€
        for model_name, model in models.items():
            print(f"ğŸ“Š {model_name} í›ˆë ¨ ì¤‘...")
            
            # ëª¨ë¸ í›ˆë ¨
            model.fit(X_train_scaled, y_train)
            
            # ì˜ˆì¸¡
            train_pred = model.predict(X_train_scaled)
            val_pred = model.predict(X_val_scaled)
            test_pred = model.predict(X_test_scaled)
            
            # í‰ê°€
            train_metrics = self.calculate_metrics(y_train, train_pred)
            val_metrics = self.calculate_metrics(y_val, val_pred)
            test_metrics = self.calculate_metrics(y_test, test_pred)
            
            # ê²°ê³¼ ì €ì¥
            self.models[model_name] = model
            self.predictions[model_name] = {
                'train': train_pred,
                'val': val_pred,
                'test': test_pred
            }
            self.evaluation_results[model_name] = {
                'train': train_metrics,
                'validation': val_metrics,
                'test': test_metrics
            }
            
            print(f"  - ê²€ì¦ RMSE: {val_metrics['rmse']:.4f}")
            print(f"  - ê²€ì¦ RÂ²: {val_metrics['r2']:.4f}")
    
    def prepare_lstm_data(self, data, feature_columns, target_column, sequence_length=60):
        """
        LSTMì„ ìœ„í•œ ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
        
        Args:
            data (pd.DataFrame): ì‹œê³„ì—´ ë°ì´í„°
            feature_columns (list): ì‚¬ìš©í•  íŠ¹ì„± ì»¬ëŸ¼ë“¤
            target_column (str): ì˜ˆì¸¡í•  ì»¬ëŸ¼
            sequence_length (int): ì‹œí€€ìŠ¤ ê¸¸ì´
            
        Returns:
            tuple: (X, y, scaler)
        """
        # ë°ì´í„° ì •ê·œí™”
        scaler = MinMaxScaler()
        scaled_data = scaler.fit_transform(data[feature_columns + [target_column]])
        
        # ì‹œí€€ìŠ¤ ìƒì„±
        X, y = [], []
        
        for i in range(sequence_length, len(scaled_data)):
            X.append(scaled_data[i-sequence_length:i, :-1])  # íŠ¹ì„±ë“¤
            y.append(scaled_data[i, -1])  # íƒ€ê²Ÿ
        
        X = np.array(X)
        y = np.array(y)
        
        print(f"âœ“ LSTM ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {X.shape}, {y.shape}")
        
        return X, y, scaler
    
    def build_lstm_model(self, input_shape, units=[50, 50], dropout_rate=0.2):
        """
        LSTM ëª¨ë¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤.
        
        Args:
            input_shape (tuple): ì…ë ¥ ë°ì´í„° í˜•íƒœ
            units (list): LSTM ë ˆì´ì–´ì˜ ìœ ë‹› ìˆ˜ë“¤
            dropout_rate (float): ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨
            
        Returns:
            tf.keras.Model: êµ¬ì„±ëœ LSTM ëª¨ë¸
        """
        model = Sequential()
        
        # ì²« ë²ˆì§¸ LSTM ë ˆì´ì–´
        model.add(LSTM(units[0], return_sequences=True, input_shape=input_shape))
        model.add(Dropout(dropout_rate))
        
        # ì¶”ê°€ LSTM ë ˆì´ì–´ë“¤
        for i in range(1, len(units)):
            return_sequences = i < len(units) - 1
            model.add(LSTM(units[i], return_sequences=return_sequences))
            model.add(Dropout(dropout_rate))
        
        # ì¶œë ¥ ë ˆì´ì–´
        model.add(Dense(1))
        
        # ì»´íŒŒì¼
        model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])
        
        return model
    
    def train_lstm_model(self, data, feature_columns, target_column='Close', 
                        sequence_length=60, prediction_days=5):
        """
        LSTM ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤. (TensorFlowê°€ ì—†ìœ¼ë©´ ê±´ë„ˆëœ€)
        
        Args:
            data (pd.DataFrame): ì‹œê³„ì—´ ë°ì´í„°
            feature_columns (list): ì‚¬ìš©í•  íŠ¹ì„± ì»¬ëŸ¼ë“¤
            target_column (str): ì˜ˆì¸¡í•  ì»¬ëŸ¼
            sequence_length (int): ì‹œí€€ìŠ¤ ê¸¸ì´
            prediction_days (int): ì˜ˆì¸¡ ì¼ìˆ˜
        """
        print("ğŸ§  LSTM ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
        print("âš ï¸ TensorFlowê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ LSTM ëª¨ë¸ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None
    
    def calculate_metrics(self, actual, predicted):
        """
        ì˜ˆì¸¡ ì„±ëŠ¥ ì§€í‘œë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Args:
            actual (array): ì‹¤ì œê°’
            predicted (array): ì˜ˆì¸¡ê°’
            
        Returns:
            dict: ì„±ëŠ¥ ì§€í‘œë“¤
        """
        mse = mean_squared_error(actual, predicted)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(actual, predicted)
        r2 = r2_score(actual, predicted)
        
        # MAPE (Mean Absolute Percentage Error)
        mape = np.mean(np.abs((actual - predicted) / actual)) * 100
        
        return {
            'mse': mse,
            'rmse': rmse,
            'mae': mae,
            'r2': r2,
            'mape': mape
        }
    
    def predict_future(self, data, model_name, days=30):
        """
        ë¯¸ë˜ ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
        
        Args:
            data (pd.DataFrame): ìµœì‹  ë°ì´í„°
            model_name (str): ì‚¬ìš©í•  ëª¨ë¸ëª…
            days (int): ì˜ˆì¸¡í•  ì¼ìˆ˜
            
        Returns:
            pd.DataFrame: ì˜ˆì¸¡ ê²°ê³¼
        """
        if model_name not in self.models:
            print(f"âŒ {model_name} ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        print(f"ğŸ”® {model_name} ëª¨ë¸ë¡œ {days}ì¼ ì˜ˆì¸¡ ì‹œì‘")
        
        model = self.models[model_name]
        
        if model_name == 'LSTM':
            return self._predict_future_lstm(data, days)
        else:
            return self._predict_future_traditional(data, model_name, days)
    
    def _predict_future_traditional(self, data, model_name, days):
        """ì „í†µì ì¸ ëª¨ë¸ë¡œ ë¯¸ë˜ ì˜ˆì¸¡"""
        model = self.models[model_name]
        scaler = self.scalers['traditional']
        
        # ìµœì‹  ë°ì´í„° ì¤€ë¹„
        feature_columns = [
            'Open', 'High', 'Low', 'Close', 'Volume',
            'MA_5', 'MA_10', 'MA_20', 'MA_50',
            'RSI', 'MACD', 'MACD_Signal',
            'BB_Upper', 'BB_Lower', 'BB_Position',
            'Daily_Return', 'Volatility',
            'DayOfWeek', 'Month', 'Quarter'
        ]
        
        lag_features = [col for col in data.columns if '_lag_' in col]
        feature_columns.extend(lag_features)
        available_features = [col for col in feature_columns if col in data.columns]
        
        latest_features = data[available_features].iloc[-1:].fillna(method='ffill')
        latest_features_scaled = scaler.transform(latest_features)
        
        # ë‹¨ì¼ ì˜ˆì¸¡ (ëª¨ë¸ì´ 5ì¼ í›„ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í›ˆë ¨ë¨)
        prediction = model.predict(latest_features_scaled)[0]
        
        # ì˜ˆì¸¡ ê²°ê³¼ ìƒì„±
        last_date = data.index[-1]
        future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=days, freq='B')
        
        # ê°„ë‹¨í•œ ì„ í˜• ë³´ê°„ìœ¼ë¡œ ì¼ë³„ ì˜ˆì¸¡ê°’ ìƒì„±
        current_price = data['Close'].iloc[-1]
        daily_change = (prediction - current_price) / 5  # 5ì¼ì— ê±¸ì¹œ ë³€í™”ë¥¼ ì¼ë³„ë¡œ ë¶„ë°°
        
        future_prices = []
        for i in range(days):
            if i < 5:
                future_price = current_price + (daily_change * (i + 1))
            else:
                # 5ì¼ ì´í›„ëŠ” ë§ˆì§€ë§‰ ì˜ˆì¸¡ê°’ ìœ ì§€ + ì•½ê°„ì˜ ë…¸ì´ì¦ˆ
                future_price = prediction + np.random.normal(0, abs(prediction) * 0.01)
            future_prices.append(future_price)
        
        future_df = pd.DataFrame({
            'Date': future_dates[:len(future_prices)],
            'Predicted_Price': future_prices
        })
        
        return future_df
    
    def _predict_future_lstm(self, data, days):
        """LSTM ëª¨ë¸ë¡œ ë¯¸ë˜ ì˜ˆì¸¡"""
        model = self.models['LSTM']
        scaler = self.scalers['LSTM']
        
        # íŠ¹ì„± ì»¬ëŸ¼ (LSTM í›ˆë ¨ ì‹œ ì‚¬ìš©í•œ ê²ƒê³¼ ë™ì¼í•´ì•¼ í•¨)
        feature_columns = ['Close', 'Volume', 'MA_20', 'RSI', 'MACD']
        available_features = [col for col in feature_columns if col in data.columns]
        
        # ìµœê·¼ 60ì¼ ë°ì´í„° ì¤€ë¹„
        sequence_length = 60
        recent_data = data[available_features].tail(sequence_length)
        
        if len(recent_data) < sequence_length:
            print(f"âŒ ì˜ˆì¸¡ì— í•„ìš”í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. í•„ìš”: {sequence_length}, í˜„ì¬: {len(recent_data)}")
            return None
        
        # ë°ì´í„° ì •ê·œí™”
        scaled_data = scaler.transform(recent_data)
        
        # ì˜ˆì¸¡ ìˆ˜í–‰
        predictions = []
        current_sequence = scaled_data[-sequence_length:, :-1]  # íƒ€ê²Ÿ ì»¬ëŸ¼ ì œì™¸
        
        for _ in range(days):
            # í˜„ì¬ ì‹œí€€ìŠ¤ë¡œ ë‹¤ìŒ ê°’ ì˜ˆì¸¡
            current_sequence_reshaped = current_sequence.reshape(1, sequence_length, -1)
            next_pred = model.predict(current_sequence_reshaped, verbose=0)[0, 0]
            predictions.append(next_pred)
            
            # ì‹œí€€ìŠ¤ ì—…ë°ì´íŠ¸ (ìƒˆ ì˜ˆì¸¡ê°’ì„ í¬í•¨)
            new_row = current_sequence[-1].copy()  # ë§ˆì§€ë§‰ íŠ¹ì„±ë“¤ ë³µì‚¬
            current_sequence = np.vstack([current_sequence[1:], new_row])
        
        # ìŠ¤ì¼€ì¼ ì—­ë³€í™˜
        dummy_array = np.zeros((len(predictions), len(available_features)))
        dummy_array[:, -1] = predictions
        predictions_original = scaler.inverse_transform(dummy_array)[:, -1]
        
        # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        last_date = data.index[-1]
        future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=days, freq='B')
        
        future_df = pd.DataFrame({
            'Date': future_dates,
            'Predicted_Price': predictions_original
        })
        
        return future_df
    
    def plot_model_comparison(self, save_path=None):
        """
        ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
        
        Args:
            save_path (str): ì €ì¥ ê²½ë¡œ
        """
        if not self.evaluation_results:
            print("âŒ í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘
        models = []
        rmse_scores = []
        r2_scores = []
        mae_scores = []
        
        for model_name, results in self.evaluation_results.items():
            if 'test' in results:
                models.append(model_name)
                rmse_scores.append(results['test']['rmse'])
                r2_scores.append(results['test']['r2'])
                mae_scores.append(results['test']['mae'])
        
        # ì‹œê°í™”
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ', fontsize=16, fontweight='bold')
        
        # 1. RMSE ë¹„êµ
        ax1 = axes[0, 0]
        bars1 = ax1.bar(models, rmse_scores, color=plt.cm.viridis(np.linspace(0, 1, len(models))))
        ax1.set_title('RMSE (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)')
        ax1.set_ylabel('RMSE')
        plt.setp(ax1.get_xticklabels(), rotation=45, ha='right')
        
        # ê°’ í‘œì‹œ
        for bar, score in zip(bars1, rmse_scores):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + score*0.01,
                    f'{score:.2f}', ha='center', va='bottom')
        
        # 2. RÂ² ë¹„êµ
        ax2 = axes[0, 1]
        bars2 = ax2.bar(models, r2_scores, color=plt.cm.plasma(np.linspace(0, 1, len(models))))
        ax2.set_title('RÂ² Score (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)')
        ax2.set_ylabel('RÂ² Score')
        plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')
        
        for bar, score in zip(bars2, r2_scores):
            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{score:.3f}', ha='center', va='bottom')
        
        # 3. MAE ë¹„êµ
        ax3 = axes[1, 0]
        bars3 = ax3.bar(models, mae_scores, color=plt.cm.coolwarm(np.linspace(0, 1, len(models))))
        ax3.set_title('MAE (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)')
        ax3.set_ylabel('MAE')
        plt.setp(ax3.get_xticklabels(), rotation=45, ha='right')
        
        for bar, score in zip(bars3, mae_scores):
            ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + score*0.01,
                    f'{score:.2f}', ha='center', va='bottom')
        
        # 4. ì¢…í•© ì„±ëŠ¥ ë ˆì´ë” ì°¨íŠ¸ (ì •ê·œí™”ëœ ì§€í‘œ)
        ax4 = axes[1, 1]
        
        # ì§€í‘œ ì •ê·œí™” (0-1 ë²”ìœ„)
        rmse_norm = 1 - np.array(rmse_scores) / max(rmse_scores)  # RMSEëŠ” ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
        mae_norm = 1 - np.array(mae_scores) / max(mae_scores)    # MAEëŠ” ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
        r2_norm = np.array(r2_scores)  # RÂ²ëŠ” ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        composite_scores = (rmse_norm + mae_norm + r2_norm) / 3
        
        bars4 = ax4.bar(models, composite_scores, color=plt.cm.Set3(np.linspace(0, 1, len(models))))
        ax4.set_title('ì¢…í•© ì„±ëŠ¥ ì ìˆ˜')
        ax4.set_ylabel('ì¢…í•© ì ìˆ˜ (0-1)')
        ax4.set_ylim(0, 1)
        plt.setp(ax4.get_xticklabels(), rotation=45, ha='right')
        
        for bar, score in zip(bars4, composite_scores):
            ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,
                    f'{score:.3f}', ha='center', va='bottom')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ’¾ ëª¨ë¸ ë¹„êµ ì°¨íŠ¸ ì €ì¥: {save_path}")
        
        plt.close()  # plt.show() ëŒ€ì‹  plt.close() ì‚¬ìš©
    
    def plot_predictions(self, data, model_name, save_path=None):
        """
        ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
        
        Args:
            data (pd.DataFrame): ì›ë³¸ ë°ì´í„°
            model_name (str): ëª¨ë¸ëª…
            save_path (str): ì €ì¥ ê²½ë¡œ
        """
        if model_name not in self.predictions:
            print(f"âŒ {model_name} ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        predictions = self.predictions[model_name]
        
        plt.figure(figsize=(15, 10))
        
        if model_name == 'LSTM':
            # LSTMì˜ ê²½ìš°
            train_actual = predictions['train_actual']
            test_actual = predictions['test_actual']
            train_pred = predictions['train']
            test_pred = predictions['test']
            
            # ì „ì²´ ë°ì´í„°ì—ì„œ í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ ì°¾ê¸°
            train_size = len(train_actual)
            total_size = train_size + len(test_actual)
            
            plt.plot(range(train_size), train_actual, label='ì‹¤ì œ (í›ˆë ¨)', color='blue', alpha=0.7)
            plt.plot(range(train_size), train_pred, label='ì˜ˆì¸¡ (í›ˆë ¨)', color='lightblue', alpha=0.7)
            plt.plot(range(train_size, total_size), test_actual, label='ì‹¤ì œ (í…ŒìŠ¤íŠ¸)', color='red', alpha=0.8)
            plt.plot(range(train_size, total_size), test_pred, label='ì˜ˆì¸¡ (í…ŒìŠ¤íŠ¸)', color='orange', alpha=0.8)
            
            plt.axvline(x=train_size, color='gray', linestyle='--', alpha=0.5, label='í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• ì ')
            
        else:
            # ì „í†µì ì¸ ëª¨ë¸ì˜ ê²½ìš° - ë” ê°„ë‹¨í•œ ì‹œê°í™”
            # ì‹¤ì œ ë°ì´í„°ì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ê³¼ ì˜ˆì¸¡ ë¹„êµ
            recent_data = data['Close'].tail(100)
            plt.plot(range(len(recent_data)), recent_data.values, label='ì‹¤ì œ ì£¼ê°€', color='blue', linewidth=2)
            
            # ì˜ˆì¸¡ ê°’ì€ í…ŒìŠ¤íŠ¸ ë¶€ë¶„ë§Œ í‘œì‹œ
            if 'test' in predictions:
                test_pred = predictions['test']
                test_start = len(recent_data) - len(test_pred)
                plt.plot(range(test_start, len(recent_data)), test_pred, 
                        label='ì˜ˆì¸¡ ì£¼ê°€', color='red', linewidth=2, alpha=0.8)
        
        plt.title(f'{model_name} ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼', fontsize=16, fontweight='bold')
        plt.xlabel('ì‹œê°„')
        plt.ylabel('ì£¼ê°€ (ì›)')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ï¿½ï¿½ ì˜ˆì¸¡ ê²°ê³¼ ì°¨íŠ¸ ì €ì¥: {save_path}")
        
        plt.close()  # plt.show() ëŒ€ì‹  plt.close() ì‚¬ìš©
    
    def save_results(self, filename_prefix="prediction_results"):
        """
        ì˜ˆì¸¡ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            filename_prefix (str): íŒŒì¼ëª… ì ‘ë‘ì‚¬
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # í‰ê°€ ê²°ê³¼ ì €ì¥
        eval_results = []
        for model_name, results in self.evaluation_results.items():
            if 'test' in results:
                eval_results.append({
                    'Model': model_name,
                    'Test_RMSE': results['test']['rmse'],
                    'Test_MAE': results['test']['mae'],
                    'Test_R2': results['test']['r2'],
                    'Test_MAPE': results['test']['mape']
                })
        
        if eval_results:
            eval_df = pd.DataFrame(eval_results)
            eval_filename = f"results/predictions/{filename_prefix}_evaluation_{timestamp}.csv"
            eval_df.to_csv(eval_filename, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ í‰ê°€ ê²°ê³¼ ì €ì¥: {eval_filename}")
        
        # ëª¨ë¸ ì €ì¥ (pickle ë“± ì‚¬ìš© ê°€ëŠ¥)
        print("ğŸ’¾ ëª¨ë¸ íŒŒì¼ë“¤ì´ results/models/ í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    predictor = StockPredictor()
    
    print("ğŸ”® ì£¼ì‹ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
    print("="*50)
    
    # ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ
    processed_files = [f for f in os.listdir('data/processed/') if f.startswith('processed_stock_data_')]
    if not processed_files:
        print("âŒ ì˜ˆì¸¡í•  ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    latest_file = max(processed_files)
    data_path = f"data/processed/{latest_file}"
    data = predictor.load_data(data_path)
    
    if data is None:
        return
    
    # íŠ¹ì • ì¢…ëª© ì„ íƒ (ì²« ë²ˆì§¸ ì¢…ëª©)
    first_symbol = data['Symbol'].unique()[0]
    stock_data = data[data['Symbol'] == first_symbol].copy()
    
    print(f"ğŸ“ˆ {stock_data['Name'].iloc[0]} ì¢…ëª© ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨")
    
    # 1. ì „í†µì ì¸ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨
    print("\n1ï¸âƒ£ ì „í†µì ì¸ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë“¤ í›ˆë ¨")
    X, y, feature_names = predictor.prepare_features(stock_data, prediction_days=5)
    X_train, X_val, X_test, y_train, y_val, y_test = predictor.split_time_series_data(X, y)
    
    predictor.train_traditional_models(X_train, X_val, X_test, y_train, y_val, y_test)
    
    # 2. LSTM ëª¨ë¸ í›ˆë ¨
    print("\n2ï¸âƒ£ LSTM ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨")
    lstm_features = ['Close', 'Volume', 'MA_20', 'RSI', 'MACD']
    available_lstm_features = [col for col in lstm_features if col in stock_data.columns]
    
    if len(available_lstm_features) >= 3:  # ìµœì†Œ 3ê°œ íŠ¹ì„± í•„ìš”
        predictor.train_lstm_model(
            stock_data, 
            available_lstm_features, 
            target_column='Close',
            prediction_days=5
        )
    else:
        print("âš ï¸ LSTM í›ˆë ¨ì— í•„ìš”í•œ íŠ¹ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    
    # 3. ê²°ê³¼ ì‹œê°í™”
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    print("\nğŸ“Š ê²°ê³¼ ì‹œê°í™”")
    predictor.plot_model_comparison(
        save_path=f"results/predictions/model_comparison_{timestamp}.png"
    )
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ ì˜ˆì¸¡ ì‹œê°í™”
    if predictor.evaluation_results:
        best_model = min(predictor.evaluation_results.keys(), 
                        key=lambda x: predictor.evaluation_results[x].get('test', {}).get('rmse', float('inf')))
        
        print(f"ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model}")
        predictor.plot_predictions(
            stock_data, 
            best_model,
            save_path=f"results/predictions/best_model_predictions_{timestamp}.png"
        )
        
        # ë¯¸ë˜ ì˜ˆì¸¡
        print(f"\nğŸ”® {best_model} ëª¨ë¸ë¡œ 30ì¼ ë¯¸ë˜ ì˜ˆì¸¡")
        future_predictions = predictor.predict_future(stock_data, best_model, days=30)
        
        if future_predictions is not None:
            future_filename = f"results/predictions/future_predictions_{timestamp}.csv"
            future_predictions.to_csv(future_filename, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ ë¯¸ë˜ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {future_filename}")
            
            # ë¯¸ë˜ ì˜ˆì¸¡ ì‹œê°í™”
            plt.figure(figsize=(12, 6))
            recent_prices = stock_data['Close'].tail(60)
            plt.plot(range(len(recent_prices)), recent_prices.values, 
                    label='ìµœê·¼ ì‹¤ì œ ì£¼ê°€', color='blue', linewidth=2)
            
            future_start = len(recent_prices)
            plt.plot(range(future_start, future_start + len(future_predictions)), 
                    future_predictions['Predicted_Price'].values,
                    label='ë¯¸ë˜ ì˜ˆì¸¡ ì£¼ê°€', color='red', linewidth=2, linestyle='--')
            
            plt.axvline(x=future_start, color='gray', linestyle=':', alpha=0.7, label='ì˜ˆì¸¡ ì‹œì‘ì ')
            plt.title(f'{stock_data["Name"].iloc[0]} ë¯¸ë˜ ì£¼ê°€ ì˜ˆì¸¡', fontsize=14, fontweight='bold')
            plt.xlabel('ì¼ìˆ˜')
            plt.ylabel('ì£¼ê°€ (ì›)')
            plt.legend()
            plt.grid(True, alpha=0.3)
            
            future_plot_path = f"results/predictions/future_prediction_plot_{timestamp}.png"
            plt.savefig(future_plot_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ’¾ ë¯¸ë˜ ì˜ˆì¸¡ ì°¨íŠ¸ ì €ì¥: {future_plot_path}")
            plt.show()
    
    # 4. ê²°ê³¼ ì €ì¥
    predictor.save_results()
    
    print("\nâœ… ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨ ë° í‰ê°€ ì™„ë£Œ!")

if __name__ == "__main__":
    main() 